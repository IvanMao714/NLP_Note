
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Attention mechanisms · Gitbook使用教程</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Ivan Mao">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="../styles/website.css">
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.html" />
    
    
    <link rel="prev" href="../4 NLM implementation/NLM implementation.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" >
            
                <a target="_blank" href="http://ivanmao.mo.cn/Learning%20Notes/index.html">
            
                    
                    Ivan Mao Learning Book
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../">
            
                <a href="../">
            
                    
                    NLP
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../0 Intro/Intro.html">
            
                <a href="../0 Intro/Intro.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../1 Language Modeling/1 Language Modeling.html">
            
                <a href="../1 Language Modeling/1 Language Modeling.html">
            
                    
                    Language Modeling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../2 Neural Language Models/Neural Language Models.html">
            
                <a href="../2 Neural Language Models/Neural Language Models.html">
            
                    
                    Neural Language Models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../3 Backpropagation/Backpropagation.html">
            
                <a href="../3 Backpropagation/Backpropagation.html">
            
                    
                    Backpropagation
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.1" data-path="../3 Backpropagation/Backpropagation(补充">
            
                <span>
            
                    
                    Backpropagation(补充)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../4 NLM implementation/NLM implementation.html">
            
                <a href="../4 NLM implementation/NLM implementation.html">
            
                    
                    NLM implementation
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.6" data-path="Attention mechanisms.html">
            
                <a href="Attention mechanisms.html">
            
                    
                    Attention mechanisms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="../6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.html">
            
                <a href="../6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.html">
            
                    
                    Transformer and sequence-to sequence learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="../7 Transfer learning with neural language models/Transfer learning with neural language models.html">
            
                <a href="../7 Transfer learning with neural language models/Transfer learning with neural language models.html">
            
                    
                    Transfer learning with neural language models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="../8 HuggingFace/HuggingFace.html">
            
                <a href="../8 HuggingFace/HuggingFace.html">
            
                    
                    HuggingFace
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Attention mechanisms</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="attention-mechanisms">Attention mechanisms</h1>
<h2 id="cons-of-rnn">Cons of RNN</h2>
<p><strong>RNNs suffer from a bottleneck problem: </strong>The current hidden representation must encode all of the information about the text observed so far</p>
<p>This becomes difficult especially with longer sequences (a vector to present whole sentence)</p>
<p><img src="img/1.png" style="zoom:75%;"></p>
<blockquote>
<p>&#x201C;you can&#x2019;t cram the meaning of a whole %&amp;@#&amp;ing sentence into a single $*(&amp;@ing vector!&#x201D;</p>
<p>&#x200B;                                                                                                                                                            &#x2014; Ray Mooney (NLP professor at UT Austin)</p>
</blockquote>
<p>what if we use multiple vectors?</p>
<p><img src="img/2.png" style="zoom:75%;"></p>
<h2 id="attention">Attention</h2>
<ul>
<li>Attention mechanisms (Bahdanau et al.,2015&#xFF09;allow language models to focus on a particular part of the observed context at each time step</li>
<li>Originally developed for machine translation, and intuitively similar to word alignments between different languages</li>
</ul>
<p>In general, we have a single query vector and multiple key vectors. We want to score each query-key pair</p>
<p><img src="img/3.png" style="zoom:75%;"></p>
<p><img src="img/4.png" style="zoom:75%;"></p>
<ul>
<li><p>Attention solves the bottleneck problem</p>
<ul>
<li>Attention allows decoder to look directly at source; bypass bottleneck</li>
</ul>
</li>
<li><p>Attention helps with vanishing gradient problem</p>
<ul>
<li>Provides shortcut to faraway states</li>
</ul>
</li>
<li><p>Attention provides some interpretability</p>
<ul>
<li>By inspecting attention distribution, we can see</li>
<li>what the decoder was focusing on</li>
<li>We get alignment for free!</li>
<li>This is cool because we never explicitly trained an alignment system</li>
<li>The network just learned alignment by itself</li>
</ul>
</li>
</ul>
<h3 id="many-variants-of-attention">Many variants of attention</h3>
<p><img src="img/5.png" style="zoom:75%;"></p>
<h2 id="self-attention">Self-attention</h2>
<p>can completely replace recurrence!</p>
<p>Each element in the sentence attends to the other elements</p>
<p><img src="img/6.png" style="zoom:75%;"></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo>=</mo><msup><mi>W</mi><mrow><mi>q</mi></mrow></msup><mo>&#x22C5;</mo><mi>P</mi></mrow><annotation encoding="application/x-tex">Q = W^{q}\cdot P  </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">Q</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">&#x22C5;</span><span class="mord mathit" style="margin-right:0.13889em;">P</span></span></span></span>        <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo>=</mo><msup><mi>W</mi><mrow><mi>k</mi></mrow></msup><mo>&#x22C5;</mo><mi>P</mi></mrow><annotation encoding="application/x-tex">K = W^{k}\cdot P </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:0.849108em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">&#x22C5;</span><span class="mord mathit" style="margin-right:0.13889em;">P</span></span></span></span></p>
<ol>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>=</mo><mi>Q</mi><mo>&#x22C5;</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">A = Q \cdot K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">A</span><span class="mrel">=</span><span class="mord mathit">Q</span><span class="mbin">&#x22C5;</span><span class="mord mathit" style="margin-right:0.07153em;">K</span></span></span></span>  &#x8BA1;&#x7B97;&#x51FA;&#x76F8;&#x5173;&#x6027;</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>M</mi><mo>=</mo><mi>A</mi><mo>(</mo><mi>P</mi><mo>)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">M = A(P)V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10903em;">M</span><span class="mrel">=</span><span class="mord mathit">A</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span>  &#x8BA1;&#x7B97;&#x51FA;&#x6700;&#x540E;&#x7684;embedding   &#x5982;&#x679C;&#x6709;&#x4F4D;&#x7F6E;&#x63A9;&#x7801;P&#xFF0C;&#x5219;&#x4E58;&#x5176;&#x503C;</li>
</ol>
<h2 id="multi-head-self-attention">Multi-head self-attention</h2>
<p><img src="img/7.png" style="zoom:75%;"></p>
<p>&#x5BFB;&#x6C42;&#x4E0D;&#x540C;&#x7684;&#x76F8;&#x5173;&#x6027;</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../4 NLM implementation/NLM implementation.html" class="navigation navigation-prev " aria-label="Previous page: NLM implementation">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.html" class="navigation navigation-next " aria-label="Next page: Transformer and sequence-to sequence learning">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Attention mechanisms","level":"1.2.6","depth":2,"next":{"title":"Transformer and sequence-to sequence learning","level":"1.2.7","depth":2,"path":"6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.md","ref":"6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.md","articles":[]},"previous":{"title":"NLM implementation","level":"1.2.5","depth":2,"path":"4 NLM implementation/NLM implementation.md","ref":"4 NLM implementation/NLM implementation.md","articles":[]},"dir":"ltr"},"config":{"plugins":["back-to-top-button","katex","chapter-fold","code","splitter","-lunr","-search","search-pro","insert-logo"],"styles":{"website":"styles/website.css"},"pluginsConfig":{"chapter-fold":{},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background: none; max-height: 30px; min-height: 30px","url":"img/logo.png"}},"theme":"default","author":"Ivan Mao","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Gitbook使用教程","language":"zh-hans","gitbook":"*","description":"学习Gitbook时总结的笔记"},"file":{"path":"5 Attention mechanisms/Attention mechanisms.md","mtime":"2022-12-26T05:17:09.732Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2023-01-31T04:26:06.263Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>


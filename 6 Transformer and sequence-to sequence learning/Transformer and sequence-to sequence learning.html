
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Transformer and sequence-to sequence learning · Gitbook使用教程</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Ivan Mao">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="../styles/website.css">
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../7 Transfer learning with neural language models/Transfer learning with neural language models.html" />
    
    
    <link rel="prev" href="../5 Attention mechanisms/Attention mechanisms.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" >
            
                <a target="_blank" href="http://ivanmao.mo.cn/Learning%20Notes/index.html">
            
                    
                    Ivan Mao Learning Book
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../">
            
                <a href="../">
            
                    
                    NLP
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../0 Intro/Intro.html">
            
                <a href="../0 Intro/Intro.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../1 Language Modeling/1 Language Modeling.html">
            
                <a href="../1 Language Modeling/1 Language Modeling.html">
            
                    
                    Language Modeling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../2 Neural Language Models/Neural Language Models.html">
            
                <a href="../2 Neural Language Models/Neural Language Models.html">
            
                    
                    Neural Language Models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../3 Backpropagation/Backpropagation.html">
            
                <a href="../3 Backpropagation/Backpropagation.html">
            
                    
                    Backpropagation
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.1" data-path="../3 Backpropagation/Backpropagation(补充">
            
                <span>
            
                    
                    Backpropagation(补充)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../4 NLM implementation/NLM implementation.html">
            
                <a href="../4 NLM implementation/NLM implementation.html">
            
                    
                    NLM implementation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../5 Attention mechanisms/Attention mechanisms.html">
            
                <a href="../5 Attention mechanisms/Attention mechanisms.html">
            
                    
                    Attention mechanisms
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.7" data-path="Transformer and sequence-to sequence learning.html">
            
                <a href="Transformer and sequence-to sequence learning.html">
            
                    
                    Transformer and sequence-to sequence learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="../7 Transfer learning with neural language models/Transfer learning with neural language models.html">
            
                <a href="../7 Transfer learning with neural language models/Transfer learning with neural language models.html">
            
                    
                    Transfer learning with neural language models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="../8 HuggingFace/HuggingFace.html">
            
                <a href="../8 HuggingFace/HuggingFace.html">
            
                    
                    HuggingFace
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Transformer and sequence-to sequence learning</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="transformer-and-sequence-to-sequence-learning">Transformer and sequence-to sequence learning</h1>
<h2 id="sequence-to-sequence-learning">sequence-to-sequence learning</h2>
<p>Used when inputs and outputs are both sequences of words (e.g., machine translation, summarization)</p>
<ul>
<li>we&#x2019;ll use French (f) to English (e) as a running example</li>
<li>goal: given French sentence f with tokens f1, f2, &#x2026; fn produce English translation e with tokens e1, e2, &#x2026; em</li>
<li>real goal: compute <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>arg</mi><msub><mi>max</mi><mrow><mi>e</mi></mrow></msub><mi>p</mi><mo>(</mo><mi>e</mi><mi mathvariant="normal">&#x2223;</mi><mi>f</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\arg\max_{e} p(e|f)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">e</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord mathit">e</span><span class="mord mathrm">&#x2223;</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mclose">)</span></span></span></span></li>
</ul>
<h3 id="seq2seq-models">seq2seq models</h3>
<ul>
<li>use two different neural networks to model<img src="img/1.png" style="zoom:40%;"></li>
<li>first we have the encoder, which encodes the French sentence f</li>
<li>then, we have the decoder, which produces the English sentence e4</li>
</ul>
<h3 id="neural-machine-translation-nmt">Neural Machine Translation (NMT)</h3>
<p><img src="img/2.png" style="zoom:75%;"></p>
<h3 id="training-a-neural-machine-translation-system">Training a Neural Machine Translation system</h3>
<p><img src="img/3.png" style="zoom:75%;"></p>
<h2 id="transformer">Transformer</h2>
<p><img src="img/4.png" style="zoom:75%;"></p>
<ul>
<li>Position embeddings are added to each word embedding. Otherwise, since we have no recurrence, our model is unaware of the position of a word in the sequence!</li>
<li>Residual connections, which mean that we add the input to a particular block to its output, help improve gradient flow</li>
<li>A feed-forward layer on top of the attention weighted averaged value vectors allows us to add more parameters / nonlinearity</li>
<li>Moving onto the decoder, which takes in English sequences that have been shifted to the right (e.g., <start> schools opened their)</start></li>
<li>the decoder is responsible for predicting the English words, we need to apply masking as we saw before.</li>
<li>we have cross attention, which connects the decoder to the encoder by enabling it to attend over the encoder&#x2019;s final hidden states.</li>
</ul>
<p>output embeding&#x662F;ground truth&#x7684;embedding&#x7ED3;&#x679C;&#xFF0C;&#xFF08;teacher forcing&#xFF1A;use ground truth as input&#xFF09;&#x4E5F;&#x5C31;&#x662F;&#x6B63;&#x786E;&#x7B54;&#x6848;&#xFF0C;&#x90A3;&#x5B58;&#x5728;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#xFF1A;&#x5728;testing&#x662F;output embedding&#x600E;&#x4E48;&#x8F93;&#x5165;&#xFF0C;&#x4E0D;&#x77E5;&#x9053;&#x6B63;&#x786E;&#x7B54;&#x6848;&#xFF1F;&#x89E3;&#x51B3;&#x529E;&#x6CD5;&#xFF1A;training&#x65F6;&#xFF0C;&#x628A;&#x6B63;&#x786E;&#x7ED3;&#x679C;&#x5F53;&#x505A;decoder&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x5728;testing&#x65F6;&#xFF0C;&#x628A;&#x4E0A;&#x4E00;&#x4E2A;&#x65F6;&#x523B;decoder&#x7684;&#x7ED3;&#x679C;&#x5F53;&#x505A;&#x5F53;&#x524D;&#x65F6;&#x523B;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x4F46;&#x662F;&#x8FD9;&#x6837;&#x5728;decoder&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x4E2D;&#xFF0C;&#x80AF;&#x5B9A;&#x5B58;&#x5728;&#x9519;&#x8BEF;&#xFF0C;&#x6240;&#x4EE5;&#x4E0D;&#x80FD;&#x8BA9;decoder&#x5728;&#x8BAD;&#x7EC3;&#x65F6;&#x53EA;&#x770B;&#x5230;&#x6B63;&#x786E;&#x7ED3;&#x679C;&#xFF0C;&#x5C31;&#x9700;&#x8981;&#x5728;training&#x65F6;&#x4EBA;&#x4E3A;&#x52A0;&#x5165;&#x4E00;&#x4E9B;&#x9519;&#x8BEF;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
<h3 id="positional-encoding">Positional encoding</h3>
<p><img src="C:\Users\65151\Desktop\NLP\6 Transformer and sequence-to sequence learning\img\5.png" style="zoom:67%;"></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../5 Attention mechanisms/Attention mechanisms.html" class="navigation navigation-prev " aria-label="Previous page: Attention mechanisms">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../7 Transfer learning with neural language models/Transfer learning with neural language models.html" class="navigation navigation-next " aria-label="Next page: Transfer learning with neural language models">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Transformer and sequence-to sequence learning","level":"1.2.7","depth":2,"next":{"title":"Transfer learning with neural language models","level":"1.2.8","depth":2,"path":"7 Transfer learning with neural language models/Transfer learning with neural language models.md","ref":"7 Transfer learning with neural language models/Transfer learning with neural language models.md","articles":[]},"previous":{"title":"Attention mechanisms","level":"1.2.6","depth":2,"path":"5 Attention mechanisms/Attention mechanisms.md","ref":"5 Attention mechanisms/Attention mechanisms.md","articles":[]},"dir":"ltr"},"config":{"plugins":["back-to-top-button","katex","chapter-fold","code","splitter","-lunr","-search","search-pro","insert-logo"],"styles":{"website":"styles/website.css"},"pluginsConfig":{"chapter-fold":{},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background: none; max-height: 30px; min-height: 30px","url":"img/logo.png"}},"theme":"default","author":"Ivan Mao","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Gitbook使用教程","language":"zh-hans","gitbook":"*","description":"学习Gitbook时总结的笔记"},"file":{"path":"6 Transformer and sequence-to sequence learning/Transformer and sequence-to sequence learning.md","mtime":"2022-12-26T08:33:40.851Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2023-01-31T04:26:06.263Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

